# Test-Agnostic Long-Tailed Recognition  

This repository is the official Pytorch implementation of [Breaking Long-Tailed Learning Bottlenecks: A Controllable Paradigm with Hypernetwork-Generated Diverse Experts](https://openreview.net/pdf?id=WpPNVPAEyv) (NeurIPS 2024).

## 1. Requirements
* To install requirements: 
```
pip install -r requirements.txt
```

## 2. Datasets
### (1) Four bechmark datasets 
* Please download these datasets and put them to the /data file.
* ImageNet-LT and Places-LT can be found at [here](https://drive.google.com/drive/u/1/folders/1j7Nkfe6ZhzKFXePHdsseeeGI877Xu1yf).
* iNaturalist data should be the 2018 version from [here](https://github.com/visipedia/inat_comp).
* CIFAR-100 will be downloaded automatically with the dataloader.

```
data
â”œâ”€â”€ ImageNet_LT
â”‚Â Â  â”œâ”€â”€ test
â”‚Â Â  â”œâ”€â”€ train
â”‚Â Â  â””â”€â”€ val
â”œâ”€â”€ CIFAR100
â”‚Â Â  â””â”€â”€ cifar-100-python
â”œâ”€â”€ Place365
â”‚Â Â  â”œâ”€â”€ data_256
â”‚Â Â  â”œâ”€â”€ test_256
â”‚Â Â  â””â”€â”€ val_256
â””â”€â”€ iNaturalist 
 Â Â  â”œâ”€â”€ test2018
    â””â”€â”€ train_val2018
```

### (2) Txt files
* We provide txt files for test-agnostic long-tailed recognition for ImageNet-LT, Places-LT and iNaturalist 2018. CIFAR-100 will be generated automatically with the code.
* For iNaturalist 2018, please unzip the iNaturalist_train.zip.
```
data_txt
â”œâ”€â”€ ImageNet_LT
â”‚Â Â  â”œâ”€â”€ ImageNet_LT_backward2.txt
â”‚Â Â  â”œâ”€â”€ ImageNet_LT_backward5.txt
â”‚Â Â  â”œâ”€â”€ ImageNet_LT_backward10.txt
â”‚Â Â  â”œâ”€â”€ ImageNet_LT_backward25.txt
â”‚Â Â  â”œâ”€â”€ ImageNet_LT_backward50.txt
â”‚Â Â  â”œâ”€â”€ ImageNet_LT_forward2.txt
â”‚Â Â  â”œâ”€â”€ ImageNet_LT_forward5.txt
â”‚Â Â  â”œâ”€â”€ ImageNet_LT_forward10.txt
â”‚Â Â  â”œâ”€â”€ ImageNet_LT_forward25.txt
â”‚Â Â  â”œâ”€â”€ ImageNet_LT_forward50.txt
â”‚Â Â  â”œâ”€â”€ ImageNet_LT_test.txt
â”‚Â Â  â”œâ”€â”€ ImageNet_LT_train.txt
â”‚Â Â  â”œâ”€â”€ ImageNet_LT_uniform.txt
â”‚Â Â  â””â”€â”€ ImageNet_LT_val.txt
â”œâ”€â”€ Places_LT_v2
â”‚Â Â  â”œâ”€â”€ Places_LT_backward2.txt
â”‚Â Â  â”œâ”€â”€ Places_LT_backward5.txt
â”‚Â Â  â”œâ”€â”€ Places_LT_backward10.txt
â”‚Â Â  â”œâ”€â”€ Places_LT_backward25.txt
â”‚Â Â  â”œâ”€â”€ Places_LT_backward50.txt
â”‚Â Â  â”œâ”€â”€ Places_LT_forward2.txt
â”‚Â Â  â”œâ”€â”€ Places_LT_forward5.txt
â”‚Â Â  â”œâ”€â”€ Places_LT_forward10.txt
â”‚Â Â  â”œâ”€â”€ Places_LT_forward25.txt
â”‚Â Â  â”œâ”€â”€ Places_LT_forward50.txt
â”‚Â Â  â”œâ”€â”€ Places_LT_test.txt
â”‚Â Â  â”œâ”€â”€ Places_LT_train.txt
â”‚Â Â  â”œâ”€â”€ Places_LT_uniform.txt
â”‚Â Â  â””â”€â”€ Places_LT_val.txt
â””â”€â”€ iNaturalist18
    â”œâ”€â”€ iNaturalist18_backward2.txt
    â”œâ”€â”€ iNaturalist18_backward3.txt
    â”œâ”€â”€ iNaturalist18_forward2.txt
    â”œâ”€â”€ iNaturalist18_forward3.txt
    â”œâ”€â”€ iNaturalist18_train.txt
    â”œâ”€â”€ iNaturalist18_uniform.txt
    â””â”€â”€ iNaturalist18_val.txt 
```


## 3. Script

### (1) ImageNet-LT
#### Training
* To train the expertise-diverse model, run this command:
```
python train.py -c configs/config_imagenet_lt_resnext50_sade.json
```

#### Evaluate
* To evaluate expertise-diverse model on the uniform test class distribution, run:
``` 
python test.py -r checkpoint_path
``` 

* To evaluate expertise-diverse model on agnostic test class distributions, run:
``` 
python test_all_imagenet.py -r checkpoint_path
``` 

#### Test-time training
* To test-time train the expertise-diverse model for agnostic test class distributions, run:
``` 
python test_training_imagenet.py -c configs/test_time_imagenet_lt_resnext50_sade.json -r checkpoint_path
``` 



### (2) CIFAR100-LT 
#### Training
* To train the expertise-diverse model, run this command:
```
python train.py -c configs/config_cifar100_ir100_sade.json
```
* One can change the imbalance ratio from 100 to 10/50 by changing the config file.

#### Evaluate
* To evaluate expertise-diverse model on the uniform test class distribution, run:
``` 
python test.py -r checkpoint_path
``` 

* To evaluate expertise-diverse model on agnostic test class distributions, run:
``` 
python test_all_cifar.py -r checkpoint_path
``` 

#### Test-time training
* To test-time train the expertise-diverse model for agnostic test class distributions, run:
``` 
python test_training_cifar.py -c configs/test_time_cifar100_ir100_sade.json -r checkpoint_path
``` 
* One can change the imbalance ratio from 100 to 10/50 by changing the config file.
 

### (3) Places-LT
#### Training
* To train the expertise-diverse model, run this command:
```
python train.py -c configs/config_places_lt_resnet152_sade.json
```

#### Evaluate
* To evaluate expertise-diverse model on the uniform test class distribution, run:
``` 
python test_places.py -r checkpoint_path
``` 

* To evaluate expertise-diverse model on agnostic test class distributions, run:
``` 
python test_all_places.py -r checkpoint_path
``` 

#### Test-time training
* To test-time train the expertise-diverse model for agnostic test class distributions, run:
``` 
python test_training_places.py -c configs/test_time_places_lt_resnet152_sade.json -r checkpoint_path
``` 

### (4) iNaturalist 2018
#### Training
* To train the expertise-diverse model, run this command:
```
python train.py -c configs/config_iNaturalist_resnet50_sade.json
```

#### Evaluate
* To evaluate expertise-diverse model on the uniform test class distribution, run:
``` 
python test.py -r checkpoint_path
``` 

* To evaluate expertise-diverse model on agnostic test class distributions, run:
``` 
python test_all_inat.py -r checkpoint_path
``` 

#### Test-time training
* To test-time train the expertise-diverse model for agnostic test class distributions, run:
``` 
python test_training_inat.py -c configs/test_time_iNaturalist_resnet50_sade.json -r checkpoint_path
``` 

## 4. Citation
If you find our work inspiring or use our codebase in your research, please cite our work.
```
@article{zhao2024breaking,
  title={Breaking Long-Tailed Learning Bottlenecks: A Controllable Paradigm with Hypernetwork-Generated Diverse Experts},
  author={Zhao, Zhe and Wen, HaiBin and Wang, Zikang and Wang, Pengkun and Wang, Fanfu and Lai, Song and Zhang, Qingfu and Wang, Yang},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={7493--7520},
  year={2024}
}
``` 

## 5. Acknowledgements
This is a project based on this [pytorch template](https://github.com/victoresque/pytorch-template). 

The mutli-expert framework are based on [RIDE](https://github.com/frank-xwang/RIDE-LongTailRecognition). The data generation of agnostic test class distributions takes references from [LADE](https://github.com/hyperconnect/LADE).



# Create the Markdown file with the frequency-domain (real-part only) NMR denoising plan
content = r"""# é¢‘åŸŸï¼ˆä»…å®éƒ¨ï¼‰NMR å»å™ªæ–¹æ¡ˆ

> é€‚ç”¨å‰æï¼šåŒä¸€æ ·æœ¬å­˜åœ¨å¤šæ¬¡å¹³è¡Œå®éªŒï¼Œå®éªŒ \(k=0,1,\dots,K\) çš„**ä¿¡å™ªæ¯”ï¼ˆSNRï¼‰æŒ‰å›ºå®šå€æ•° \(T>1\)** é€æ­¥æå‡ã€‚æ¯æ¡è°±æ˜¯**é¢‘åŸŸå®éƒ¨**ï¼ˆreal-valued 1Dï¼‰ã€‚æ‰€æœ‰è°±åœ¨é‡‡é›†åå‡åšè¿‡**å½’ä¸€åŒ–**ï¼ˆä½†å½’ä¸€åŒ–æ–¹å¼å¯èƒ½ä¸åŒï¼‰ã€‚ç›®æ ‡ï¼šå­¦ä¹ å»å™ªæ˜ å°„ \(f_\theta\)ï¼Œä½¿å…¶åœ¨åŸå§‹ä½ SNR è¾“å…¥ä¸Šè¾“å‡ºæ›´æ¥è¿‘çœŸå®å…‰è°±ã€ä¿å³°ä¿çº¿å‹ã€ç¨³åŸºçº¿ã€‚

---

## 1. æ•°æ®å»ºæ¨¡ä¸è®°å·

- ç¬¬ \(k\) æ¬¡å®éªŒçš„æœªå½’ä¸€åŒ–é¢‘åŸŸå®éƒ¨è®°ä¸º \(\tilde{x}^{(k)}\in\mathbb{R}^L\)ï¼ˆé•¿åº¦ \(L\)ï¼‰ï¼š  
  $$
  \tilde{x}^{(k)} \;=\; a_k\, s \;+\; b_k\, n^{(k)},\qquad k=0,\dots,K,
  $$
  å…¶ä¸­ \(s\) ä¸ºç†æƒ³çœŸå®å…‰è°±ï¼ˆåŒä¸€æ ·æœ¬ä¸å˜ï¼‰ï¼Œ\(n^{(k)}\) ä¸ºé›¶å‡å€¼å™ªå£°ï¼›ç›¸é‚»å®éªŒçš„ SNR æ»¡è¶³  
  $$
  \frac{a_{k+1}/b_{k+1}}{a_k/b_k} \;\approx\; T\;>\;1.
  $$

- å®é™…å¯ç”¨æ•°æ®ä¸ºå½’ä¸€åŒ–åçš„ \(x^{(k)}=\mathrm{norm}(\tilde{x}^{(k)})\)ã€‚ç”±äºå½’ä¸€åŒ–å¯èƒ½æ”¹å˜å¹…åº¦å°ºåº¦ï¼Œåç»­æˆ‘ä»¬ä¼šåœ¨**å³°åŒº**åš**é²æ£’å¹…åº¦é‡æ ‡å®š**ä»¥ä¾¿å¯æ¯”ã€‚

- è®­ç»ƒç›®æ ‡ï¼šå­¦ä¹  \(f_\theta:\mathbb{R}^L\!\to\!\mathbb{R}^L\)ï¼Œä»¤ \(f_\theta(x^{(0)})\) åœ¨å°ºåº¦å¯æ¯”çš„æ„ä¹‰ä¸‹é€¼è¿‘ \(s\)ã€‚

> è‹¥åªæœ‰é¢‘åŸŸå¹…åº¦è°±ï¼ˆå®éƒ¨ï¼‰ï¼Œç›´æ¥åœ¨é¢‘åŸŸåš 1D å»å™ªï¼›è‹¥ä¹‹åæ‹¥æœ‰æ—¶åŸŸ FIDï¼Œå¯æ‰©å±•ä¸ºåŒåŸŸè®­ç»ƒã€‚

---

## 2. é¢‘åŸŸé¢„å¤„ç†æµç¨‹ï¼ˆä»…å®éƒ¨ï¼‰

### 2.1 é¢‘è½´å¯¹é½ï¼ˆppm shift æ ¡æ­£ï¼‰
å¯¹åŒä¸€æ ·æœ¬çš„ \(\{x^{(k)}\}\) åšäºšåƒç´ å¯¹é½ï¼Œé¿å…å³°ä½æ¼‚ç§»å½±å“èåˆä¸æŸå¤±ï¼š
- ä½¿ç”¨**ç›¸ä½äº’ç›¸å…³**æˆ–**äº’ç›¸å…³å³°å®šä½**æ±‚ç›¸å¯¹ä½ç§» \(\Delta \tau_k\)ï¼Œå¯¹è°±ä½œå¾ªç¯å¹³ç§»æˆ–çº¿æ€§æ’å€¼æ ¡æ­£ï¼›
- å¦‚å­˜åœ¨å±€éƒ¨éçº¿æ€§æ¼‚ç§»ï¼Œå¯åœ¨è‹¥å¹²**é”šå³°çª—å£**å†…åš**å±€éƒ¨å¯¹é½**ï¼ˆä¼˜å…ˆå¯¹å¼ºå³°ï¼‰ã€‚

### 2.2 é²æ£’å¹…åº¦é‡æ ‡å®šï¼ˆè·¨ \(k\) ä½¿å³°åŒºå¯æ¯”ï¼‰
å½’ä¸€åŒ–ç ´åäº†åŸå¹…åº¦æ¯”ä¾‹ã€‚è®¾ \(x^{(K)}\) ä¸ºæœ€é«˜ SNR è°±ï¼ˆæˆ– Â§3.1 çš„åŠ æƒèåˆä¼ªçœŸå€¼ï¼‰ã€‚åœ¨â€œå€™é€‰å³°åŒºâ€æ©ç  \(M\in\{0,1\}^L\) å†…ï¼Œç”¨æœ€å°äºŒä¹˜æ±‚æ¯æ¡è°±çš„**æ ‡å®šç³»æ•°** \(s_k\)ï¼š  
$$
s_k \;=\; \arg\min_{s>0}\; \sum_{i=1}^{L} M_i \,\big(s\,x^{(k)}_i - x^{(K)}_i\big)^2
\;=\;
\frac{\sum_i M_i\, x^{(K)}_i\, x^{(k)}_i}{\sum_i M_i\, \big(x^{(k)}_i\big)^2}.
$$
é‡æ ‡å®šå \(\bar{x}^{(k)}=s_k\,x^{(k)}\)ã€‚

> è‹¥ä¸æƒ³ä»¥ \(x^{(K)}\) ä½œå‚ç…§ï¼Œå¯å…ˆåšä¸€æ¬¡â€œèåˆä¼ªçœŸå€¼â€ï¼ˆè§ Â§3.1ï¼‰å†å›åˆ°æ­¤æ­¥é‡æ ‡å®šã€‚

### 2.3 å³°åŒº/åŸºçº¿åŒºè‡ªåŠ¨åˆ†å‰²ï¼ˆå³°æ©ç  \(M\) ä¸åŸºçº¿æ©ç  \(B\)ï¼‰
1. **å¹³æ»‘**ï¼šå¦‚ Savitzkyâ€“Golay å¾—åˆ° \(x^{(k)}_{\text{smooth}}\)ï¼›  
2. **å€™é€‰å³°æ£€æµ‹**ï¼šå¯¹ \(\{\bar{x}^{(k)}\}\) å–é€ç‚¹æœ€å¤§ \(\max_k \bar{x}^{(k)}\)ï¼›  
3. è®¡ç®—è‡ªé€‚åº”é˜ˆå€¼ \(\tau = \mathrm{median} + \alpha \cdot \mathrm{MAD}\)ï¼ˆ\(\alpha\in[3,5]\)ï¼‰ï¼›  
4. ä»¤ \(M_i=\mathbf{1}\{\max_k \bar{x}^{(k)}_i\ge \tau\}\)ï¼Œå†**å½¢æ€å­¦è†¨èƒ€**è‹¥å¹²ç‚¹ä»¥è¦†ç›–å³°è£™ï¼›  
5. åŸºçº¿æ©ç  \(B\) å– \(M\) çš„è¡¥é›†ï¼Œå¹¶**è…èš€** 1â€“2 ç‚¹é¿å…å³°è„šæ¼å…¥ã€‚

### 2.4 å™ªå£°å¼ºåº¦ä¸ SNR ä¼°è®¡ï¼ˆåœ¨ \(B\) å†…ï¼‰
åŸºçº¿å™ªå£°æ ‡å‡†å·®ï¼ˆé²æ£’ï¼‰ï¼š  
$$
\sigma_k \;=\; 1.4826 \cdot \mathrm{median}\Big(\,\big|\bar{x}^{(k)}_i - \mathrm{median}(\bar{x}^{(k)}_{B})\big| \;:\; i\in B\Big).
$$
ç¨³å¥ SNRï¼ˆç”¨äºæƒé‡ï¼‰ï¼š  
$$
\mathrm{SNR}_k \;=\; \frac{\mathrm{P95}\big(\bar{x}^{(k)}_{M}\big) - \mathrm{median}\big(\bar{x}^{(k)}_{B}\big)}{\sigma_k}.
$$

> å¯æ® \(\sigma_k\) **è‡ªé€‚åº”ä¼°è®¡** \(T\)ï¼š\(\widehat{T}\approx \mathrm{median}_k(\sigma_k/\sigma_{k+1})\)ã€‚

---

## 3. ç›‘ç£ç›®æ ‡ï¼ˆé¢‘åŸŸå®éƒ¨ï¼‰

### 3.1 ä¼ªçœŸå€¼ï¼ˆæ–¹æ¡ˆ Sï¼‰ï¼šå¤š SNR èåˆ
ç”¨ \(\{\bar{x}^{(k)}\}\) åœ¨é¢‘åŸŸåšåŠ æƒå¾—åˆ°ä¼ªçœŸå€¼ \(\hat{s}\)ï¼š  
$$
\hat{s}_i \;=\;
\frac{\sum_{k=0}^{K} w_k \,\bar{x}^{(k)}_i}{\sum_{k=0}^{K} w_k},
\qquad
w_k \;\propto\; \mathrm{SNR}_k^{\,\gamma}\;\; \text{æˆ–}\;\; T^{k},\;\; \gamma\in[0.5,1.5].
$$
ä¸ºæŠ‘åˆ¶æ®‹å™ªæ”¾å¤§ï¼Œå»ºè®®**ä¸Šé™æˆªæ–­**ï¼š\(w_k\leftarrow \min(w_k, w_{\max})\)ã€‚

> ç®€åŒ–é€‰é¡¹ï¼šè‹¥æœ€é«˜ SNR è°±è´¨é‡å·²è¶³å¤Ÿï¼Œå¯ç›´æ¥å– \(\hat{s}=\bar{x}^{(K)}\)ã€‚

### 3.2 è‡ªç›‘ç£ä¸€è‡´æ€§ï¼ˆæ–¹æ¡ˆ Uï¼‰ï¼šå¤š SNR å¯¹é½
å¯¹åŒä¸€æ ·æœ¬çš„å¤š SNR è°±ç»æ¨¡å‹è¾“å‡ºåï¼Œåœ¨é¢‘åŸŸç›´æ¥å¯¹é½ï¼š  
$$
\mathcal{L}_{\mathrm{cons}} \;=\;
\frac{1}{\binom{K+1}{2}}
\sum_{0\le i<j\le K}
\Big\|\, f_\theta(\bar{x}^{(i)}) - f_\theta(\bar{x}^{(j)}) \Big\|_{1}.
$$

### 3.3 æ®‹å·®æ¯”ä¾‹è½¯çº¦æŸï¼ˆç”¨ \(T\) çš„å…ˆéªŒï¼‰
å®šä¹‰æ®‹å·® \(r^{(k)}=\bar{x}^{(k)}-f_\theta(\bar{x}^{(k)})\)ã€‚åœ¨**åŸºçº¿åŒº \(B\)** æ§åˆ¶èƒ½é‡æ¯”ï¼š  
$$
\mathcal{R}_{ij} \;=\; 
\frac{\| r^{(i)}\odot B \|_2}{\| r^{(j)}\odot B \|_2 + \varepsilon},
\qquad
\alpha_{ij} \;\approx\; T^{-(j-i)}.
$$
åŠ å…¥è½¯çº¦æŸæŸå¤±ï¼ˆå–å¯¹æ•°å¯ç¨³å®šï¼‰ï¼š  
$$
\mathcal{L}_{T} \;=\;
\frac{1}{\binom{K+1}{2}}
\sum_{i<j} \Big| \log \mathcal{R}_{ij} - \log \alpha_{ij} \Big|.
$$

---

## 4. æ¨¡å‹ç»“æ„ï¼ˆé¢‘åŸŸ 1Dï¼Œå®éƒ¨ï¼‰

### 4.1 æ®‹å·®å¼ 1D U-Netï¼ˆæ¨èï¼‰
- **è¾“å…¥/è¾“å‡º**ï¼š\(\mathbb{R}^{L}\to\mathbb{R}^{L}\)ã€‚è¾“å‡ºè¡¨ç¤º**å»å™ªåçš„è°±**ï¼ˆä¹Ÿå¯è¾“å‡ºå™ªå£°æ®‹å·®ï¼Œæ¨ç†æ—¶è¾“å…¥å‡æ®‹å·®ï¼‰ã€‚  
- **ç¼–ç å™¨ï¼ˆ4 å±‚ï¼‰**ï¼šæ¯å±‚ Conv1D(k=9, dilation=1/2/4/8) + Norm(Group/LayerNorm) + GELU + æ®‹å·®ï¼Œstride 2 ä¸‹é‡‡æ ·ã€‚  
- **è§£ç å™¨ï¼ˆ4 å±‚ï¼‰**ï¼šè½¬ç½®å·ç§¯ä¸Šé‡‡æ · + è·³è¿ï¼ˆconcat ç¼–ç å™¨åŒçº§ç‰¹å¾ï¼‰+ æ®‹å·®å—ã€‚  
- **é€šé“æ•°**ï¼š64â†’128â†’256â†’256ï¼ˆç“¶é¢ˆï¼‰â†’â€¦â†’64ã€‚  
- **æ³¨æ„åŠ›ï¼ˆå¯é€‰ï¼‰**ï¼šSE/CBAM 1D æ”¾åœ¨ç“¶é¢ˆä¸æµ…å±‚ä»¥å¢å¼ºå³°åŒºè¡¨è¾¾ã€‚  
- **è¾“å‡ºå¤´**ï¼šConv1D(k=1)ï¼›çº¿æ€§æˆ– `tanh` åä¸è¾“å…¥åšçŸ­è·¯æ®‹å·®ã€‚

> 1D åºåˆ—é€šå¸¸å¯¹è½»é‡æ¨¡å‹å‹å¥½ï¼›æ€»å‚æ•°é‡ 1â€“3M è¶³å¤Ÿã€‚

---

## 5. é¢‘åŸŸæŸå¤±è®¾è®¡ï¼ˆä»…å®éƒ¨ï¼‰

ä»¤ \(y^{(k)} = f_\theta(\bar{x}^{(k)})\)ã€‚

### 5.1 é‡å»ºä¸çº¿å‹ä¿æŒï¼ˆå¯¹ä¼ªçœŸå€¼ï¼‰
- **é‡å»ºæŸå¤±**ï¼ˆå¯¹ç›®æ ‡æ ·æœ¬ \(k=0\) å¿…é€‰ï¼›å…¶ä½™æ ·æœ¬å¯é‡‡æ ·ä½¿ç”¨ï¼‰ï¼š  
  $$
  \mathcal{L}_{\mathrm{rec}} \;=\;
  \big\|\, y^{(0)} - \hat{s} \,\big\|_{1}.
  $$
- **ä¸€é˜¶å¯¼æ•°æŸå¤±**ï¼ˆä¿å³°å½¢ï¼‰ï¼š  
  $$
  \mathcal{L}_{\mathrm{deriv}} \;=\;
  \big\|\nabla y^{(0)} - \nabla \hat{s}\big\|_{1},\quad
  \nabla y_i = y_{i+1}-y_i.
  $$
- **å³°åŒºæƒé‡**ï¼šå¯¹å³°æ©ç  \(M\) å†…æƒé‡æ”¾å¤§ï¼Œå½¢æˆåŠ æƒ \(L_1\)ï¼ˆå¦‚å³°åŒº \(\times 6\)ï¼ŒåŸºçº¿ \(\times 1\)ï¼‰ã€‚

### 5.2 åŸºçº¿ç¨³å¥ä¸å¹³æ»‘
- **äºŒé˜¶å·®åˆ†æ­£åˆ™ï¼ˆä»…åœ¨åŸºçº¿åŒºï¼‰**ï¼š  
  $$
  \mathcal{L}_{\mathrm{curv}} \;=\;
  \big\|\Delta y^{(0)}\odot B\big\|_{1},\quad
  \Delta y_i = y_{i+1}-2y_i+y_{i-1}.
  $$

### 5.3 å¤š SNR ä¸€è‡´æ€§ä¸ \(T\) çº¦æŸ
- **ä¸€è‡´æ€§æŸå¤±**ï¼š\(\mathcal{L}_{\mathrm{cons}}\)ï¼ˆÂ§3.2ï¼‰ï¼Œå¯åœ¨æ‰€æœ‰ \(k\) ä¸Šé‡‡æ ·è®¡ç®—ã€‚  
- **\(T\) è½¯çº¦æŸ**ï¼š\(\mathcal{L}_{T}\)ï¼ˆÂ§3.3ï¼‰ï¼Œä»…åœ¨ \(B\) å†…åŸºäºèƒ½é‡æ¯”ã€‚

### 5.4 æ€»æŸå¤±ï¼ˆç¤ºä¾‹æƒé‡ï¼‰
$$
\mathcal{L}
=
\underbrace{\mathcal{L}_{\mathrm{rec}} + \lambda_1 \mathcal{L}_{\mathrm{deriv}} + \lambda_2 \mathcal{L}_{\mathrm{curv}}}_{\text{ç›‘ç£ï¼ˆå¯¹ }k=0\text{ ä¸ä¼ªçœŸå€¼ï¼‰}}
\;+\;
\underbrace{\lambda_3 \mathcal{L}_{\mathrm{cons}} + \lambda_4 \mathcal{L}_{T}}_{\text{è‡ªç›‘ç£ï¼ˆè·¨ }k\text{ ä¸€è‡´ä¸ }T\text{ çº¦æŸï¼‰}}.
$$

å»ºè®®åˆå§‹æƒé‡ï¼š\(\lambda_1=0.5,\; \lambda_2=0.1,\; \lambda_3=0.5,\; \lambda_4=0.2\)ã€‚

---

## 6. è®­ç»ƒç­–ç•¥ï¼ˆä¸¤é˜¶æ®µï¼‰

### é˜¶æ®µ Aï¼ˆç›‘ç£/å¼±ç›‘ç£ä¸ºä¸»ï¼Œ30â€“50 epochï¼‰
- ä»¥ \(\hat{s}\)ï¼ˆÂ§3.1ï¼‰ä½œä¸ºä¼ªçœŸå€¼ï¼Œä¸»è®­ç»ƒ \(\mathcal{L}_{\mathrm{rec}}+\lambda_1\mathcal{L}_{\mathrm{deriv}}+\lambda_2\mathcal{L}_{\mathrm{curv}}\)ã€‚  
- æ‰¹æ¬¡ä¸­é™¤ \(k=0\) å¤–ï¼Œéšæœºé‡‡æ · 1â€“2 æ¡ \(k>0\) è°±å‚ä¸ \(\mathcal{L}_{\mathrm{cons}}\)ã€‚

### é˜¶æ®µ Bï¼ˆè‡ªç›‘ç£å¢å¼ºï¼Œ40â€“70 epochï¼‰
- åŠ å¤§ \(\lambda_3\)ï¼ˆä¸€è‡´æ€§ï¼‰ä¸ \(\lambda_4\)ï¼ˆ\(T\) è½¯çº¦æŸï¼‰ï¼Œå……åˆ†åˆ©ç”¨å…¨éƒ¨ \(k\)ã€‚  
- **SNR è¯¾ç¨‹å­¦ä¹ **ï¼šå…ˆç”¨é«˜ SNR å¯¹ï¼ˆå¤§ \(k\)ï¼‰ï¼Œå†é€æ­¥åŠ å…¥ä½ SNR å¯¹ï¼ˆå° \(k\)ï¼‰ã€‚  
- è®­ç»ƒåæœŸå¯ä¸Šè°ƒå³°åŒºæƒé‡ï¼Œæˆ–ä¸‹è°ƒ \(\lambda_2\) é˜²æ­¢è¿‡æŠ¹å³°ã€‚

**ä¼˜åŒ–å™¨ä¸è°ƒåº¦ï¼ˆå»ºè®®ï¼‰**ï¼šAdamWï¼ˆlr=3e-4ï¼Œwd=1e-4ï¼‰ï¼Œcosine decayï¼Œwarmup 5 epochã€‚  
**æ‰¹æ¬¡æ„æˆ**ï¼šåŒä¸€ batch å†…å°½é‡åŒ…å«**åŒä¸€æ ·æœ¬çš„å¤š SNR**ï¼ˆåˆ©äºä¸€è‡´æ€§è®¡ç®—ï¼‰ã€‚

---

## 7. è¯„æµ‹æŒ‡æ ‡ï¼ˆé¢‘åŸŸï¼Œä»…å®éƒ¨ï¼‰

1. **SNR æå‡**ï¼ˆç»Ÿä¸€çª—å£ï¼‰ï¼š  
   \(\mathrm{SNR}_{\mathrm{out}} = \dfrac{\mathrm{P95}(y_M)-\mathrm{median}(y_B)}{\mathrm{std}(y_B)}\)ï¼Œä¸è¾“å…¥/ä¼ªçœŸå€¼å¯¹æ¯”ã€‚
2. **å³°æ£€æµ‹/å®šä½**ï¼šå¯¹ \(y^{(0)}\) ä¸ \(\hat{s}\) åšå³°åŒ¹é…ï¼ˆå®¹å¿ \(\pm\Delta\) ppmï¼‰ï¼Œç»Ÿè®¡ Precision/Recall/F1ã€å®šä½è¯¯å·®ã€‚
3. **çº¿å‹é‡åŒ–**ï¼šä¸»å³° **FWHM** ä¸**ç§¯åˆ†é¢ç§¯**ç›¸å¯¹è¯¯å·®ã€‚
4. **æ•´ä½“å¤±çœŸ**ï¼š\(\|y^{(0)}-\hat{s}\|_1,\;\|y^{(0)}-\hat{s}\|_2\)ã€‚

---

## 8. æ¶ˆèå»ºè®®

- **å³°åŒºæƒé‡**ï¼š\(+/-\) å³°æ©ç åŠ æƒã€‚  
- **\(\mathcal{L}_{\mathrm{curv}}\)**ï¼šåŸºçº¿ç¨³å®šæ€§å¯¹æ¯”ã€‚  
- **ä¸€è‡´æ€§/ \(T\) çº¦æŸ**ï¼šå»æ‰ \(\mathcal{L}_{\mathrm{cons}}\)ã€\(\mathcal{L}_T\) çš„å½±å“ã€‚  
- **ä¼ªçœŸå€¼ç­–ç•¥**ï¼šä»… \(k=K\) vs SNR åŠ æƒèåˆã€‚  
- **é‡æ ‡å®š**ï¼šæœ‰/æ—  Â§2.2 çš„ \(s_k\) æ ‡å®šå¯¹æ•ˆæœçš„å½±å“ã€‚

---

## 9. è®­ç»ƒä¸»å¾ªç¯ï¼ˆé¢‘åŸŸä¼ªä»£ç ï¼ŒPyTorch é£æ ¼ï¼‰

```python
# x_list: [B, K+1, L]  â€”â€” å·²å¯¹é½ä¸é‡æ ‡å®šï¼ˆÂ§2.1/2.2ï¼‰ï¼›
# mask_peak, mask_base: [B, L]ï¼›s_hat: [B, L]ï¼ˆÂ§3.1ï¼‰

for epoch in range(num_epochs):
    for x_list, mask_peak, mask_base, s_hat in loader:
        x0 = x_list[:, 0, :]          # ä½SNRè¾“å…¥
        y0 = model(x0)                # å»å™ªè¾“å‡º

        # å³°/åŸºçº¿åŠ æƒ
        w_peak, w_base = 6.0, 1.0
        W = w_base*mask_base + w_peak*mask_peak

        # é‡å»º + ä¸€é˜¶å¯¼æ•°
        L_rec   = (W * (y0 - s_hat).abs()).mean()

        def diff1(z): return z[..., 1:] - z[..., :-1]
        L_deriv = (diff1(y0) - diff1(s_hat)).abs().mean()

        # åŸºçº¿äºŒé˜¶å·®åˆ†ï¼ˆä»…åœ¨Bå†…ï¼‰
        def diff2(z): return z[..., 2:] - 2*z[..., 1:-1] + z[..., :-2]
        L_curv  = (diff2(y0) * mask_base[..., 1:-1]).abs().mean()

        # å¤šSNRä¸€è‡´æ€§ï¼ˆéšæœºé‡‡ 1-2 æ¡é«˜SNRä½œä¸ºå¯¹ç…§ï¼‰
        y_all = []
        idxs = sample_indices_from_1_to_K(x_list.shape[1])
        for j in idxs:
            y_all.append(model(x_list[:, j, :]))
        L_cons = 0.0
        if len(y_all) >= 2:
            cnt = 0
            for i in range(len(y_all)):
                for j in range(i+1, len(y_all)):
                    L_cons += (y_all[i] - y_all[j]).abs().mean()
                    cnt += 1
            L_cons /= max(1, cnt)

        # æ®‹å·®æ¯”ä¾‹è½¯çº¦æŸï¼ˆåœ¨åŸºçº¿åŒºï¼‰
        eps = 1e-8
        L_T = 0.0; cnt = 0
        for i in range(len(y_all)):
            for j in range(i+1, len(y_all)):
                ri = (x_list[:, i+1, :] - y_all[i]) * mask_base
                rj = (x_list[:, j+1, :] - y_all[j]) * mask_base
                num = (ri.pow(2).sum(dim=-1).sqrt() + eps)
                den = (rj.pow(2).sum(dim=-1).sqrt() + eps)
                ratio = num / den
                alpha = (T ** (-(j - i))) * torch.ones_like(ratio)
                L_T += ( (ratio+eps).log() - (alpha+eps).log() ).abs().mean()
                cnt += 1
        L_T /= max(1, cnt)





# 3.æ¨¡å‹ä»‹ç»

# 3.1 æ¨¡å‹è®¾å®š

æœ¬æ–‡ä¸»è¦ç ”ç©¶ä¸‰ä¸ªå­ç»„çš„åˆ†ç»„æƒ…å†µï¼Œä»¥ $\delta _ { i }$ è¡¨ç¤ºå­ç»„ä¸ªæ•°ä¸” $\delta _ { i } \in \{ 1 , 2 , 3 \}$ ã€‚éšæœºæ•ˆåº” $b _ { i }$ çš„åæ–¹å·®çŸ©é˜µä¸º $\sigma _ { b } ^ { 2 }$ ï¼Œ $\delta _ { i } = 1$ å¯¹åº”éšæœºæ•ˆåº” $b _ { i }$ çš„å‡å€¼ä¸º $\mu _ { 1 }$ ï¼Œ $\delta _ { i } = 2$ å¯¹åº”éšæœºæ•ˆåº” $b _ { i }$ çš„å‡å€¼ä¸º $\mu _ { 2 }$ ï¼Œå½“$\delta _ { i } = 3$ å¯¹åº”éšæœºæ•ˆåº” $b _ { i }$ çš„å‡å€¼ä¸º $\mu _ { 3 }$ ã€‚æ­¤æ—¶å¯¹åº”å­ç»„çš„æ¦‚ç‡å¦‚ä¸‹ï¼š

$$
P ( \delta _ { i } = k | U _ { i } ) = \frac { e ^ { U _ { i } \gamma _ { k } } } { \sum _ { k = 1 } ^ { 3 } e ^ { U _ { i } \gamma _ { k } } } , k = 1 , 2 , 3
$$

å„å­ç»„çš„æ¦‚ç‡åˆ†åˆ«å¦‚ä¸‹ï¼š

$$
\begin{array} { l } { P ( \delta _ { i } = 1 | U _ { i } ) = \displaystyle \frac { e ^ { U _ { i } \gamma _ { 1 } } } { e ^ { U _ { i } \gamma _ { 1 } } + e ^ { U _ { i } \gamma _ { 2 } } + e ^ { U _ { i } \gamma _ { 3 } } } } \\ { P ( \delta _ { i } = 2 | U _ { i } ) = \displaystyle \frac { e ^ { U _ { i } \gamma _ { 2 } } } { e ^ { U _ { i } \gamma _ { 1 } } + e ^ { U _ { i } \gamma _ { 2 } } + e ^ { U _ { i } \gamma _ { 3 } } } } \\ { P ( \delta _ { i } = 3 | U _ { i } ) = \displaystyle \frac { e ^ { U _ { i } \gamma _ { 3 } } } { e ^ { U _ { i } \gamma _ { 1 } } + e ^ { U _ { i } \gamma _ { 2 } } + e ^ { U _ { i } \gamma _ { 3 } } } } \end{array}
$$

# 3.1.4 æ½œåœ¨å­ç»„æ¡ä»¶æ¨¡å‹

ä¸ºç®€åŒ–åˆ†æè¿‡ç¨‹ï¼Œæœ¬æ–‡åªè€ƒè™‘ä¸ªä½“é—´å¼‚è´¨æ€§é€ æˆçš„éšæœºæ•ˆåº”ï¼Œä¸é’ˆå¯¹ä¸ªä½“å†…å¼‚è´¨æ€§è¿›ä¸€æ­¥åˆ†æã€‚å¼•å…¥æ½œåœ¨å­ç»„ $\delta _ { i }$ ï¼Œè€ƒè™‘ä¸‰ä¸ªå­ç»„çš„æƒ…å†µå³ $| \delta _ { i } \in \{ 1 , 2 , 3 \}$ ï¼Œæ½œåœ¨å­ç»„å¯ä»¥é€šè¿‡ä¸åˆ†ç»„ç›¸å…³çš„åå˜é‡ $U _ { i }$ çš„é€»è¾‘å›å½’æ„å»ºæ¨¡å‹ï¼Œå¹¶å°†éšæœºæ•ˆåº”çœ‹ä½œæ˜¯æ¥è‡ªä¸‰ä¸ªå‡å€¼ä¸åŒï¼Œæ–¹å·®ç›¸åŒçš„æ­£æ€åˆ†å¸ƒå³ $b _ { i } { \sim } N ( \mu _ { k } , \sigma _ { b } ^ { 2 } )$ ï¼Œåˆ™éšæœºæ•ˆåº”çš„æœ‰é™æ··åˆåˆ†å¸ƒï¼š

$$
g ( b ) = \sum _ { k = 1 } ^ { 3 } p _ { k } g _ { k } ( b )
$$

å…¶ä¸­ï¼Œ $\begin{array} { r } { g _ { k } ( b ) = \frac { 1 } { \sqrt { 2 \pi \sigma _ { b } ^ { 2 } } } e x p \left[ - \frac { ( b - \mu _ { k } ) ^ { 2 } } { 2 \sigma _ { b } ^ { 2 } } \right] \circ } \end{array}$ ä¸æ··åˆå­ç»„ç›¸å¯¹åº”çš„æ¯”ä¾‹ä¸ºå¸¸æ•° ${ \cdot } p _ { k } \ge 0 ( k = 1 , 2 , 3 )$ ï¼Œä¸”æ»¡è¶³ $\begin{array} { r } { \sum _ { k = 1 } ^ { 3 } p _ { k } = 1 } \end{array}$ ã€‚å¼•å…¥æ½œåœ¨å­ç»„ $\delta _ { i }$ çš„æ¡ä»¶æ¨¡å‹çŸ©é˜µå½¢å¼å¦‚ä¸‹ï¼š

$$
y _ { i } | ( \delta _ { i } , U _ { i } , W _ { i } , b _ { i } ) = \left( \begin{array} { c c c c } { W _ { i 1 1 } } & { W _ { i 1 2 } } & { \cdots } & { W _ { i 1 p } } \\ { W _ { i 2 1 } } & { W _ { i 2 2 } } & { \cdots } & { W _ { i 2 p } } \\ { \vdots } & { \vdots } & { \vdots } \\ { W _ { i t 1 } } & { W _ { i t 2 } } & { \cdots } & { W _ { i t p } } \end{array} \right) \left( \begin{array} { c } { \alpha _ { 1 } } \\ { \alpha _ { 2 } } \\ { \vdots } \\ { \alpha _ { p } } \end{array} \right) + \left( \begin{array} { c } { 1 } \\ { 1 } \\ { \vdots } \\ { 1 } \end{array} \right) b _ { i } + \left( \begin{array} { c } { \varepsilon _ { i 1 } } \\ { \varepsilon _ { i 2 } } \\ { \vdots } \\ { \varepsilon _ { i t } } \end{array} \right)
$$

ä»¤ $W _ { i } = \left( \begin{array} { c c c c } { W _ { i 1 1 } } & { W _ { i 1 2 } } & { \cdots } & { W _ { i 1 p } } \\ { W _ { i 2 1 } } & { W _ { i 2 2 } } & { \cdots } & { W _ { i 2 p } } \\ { \vdots } & { \vdots } & { } & { \vdots } \\ { W _ { i t 1 } } & { W _ { i t 2 } } & { \cdots } & { W _ { i t p } } \end{array} \right)$ è¡¨ç¤ºå›ºå®šæ•ˆåº”çš„è®¾è®¡çŸ©é˜µï¼Œ $W _ { i } \in R ^ { t \times p }$ ï¼› $\alpha =$ $( \alpha _ { 1 } , \alpha _ { 2 } , \cdots , \alpha _ { q } ) ^ { T }$ è¡¨ç¤ºå›ºå®šæ•ˆåº”ï¼Œ $\alpha \in R ^ { p \times 1 }$ ï¼›éšæœºæ•ˆåº” $b _ { i } { \sim } N ( \mu _ { k } , \sigma _ { b } ^ { 2 } )$ ï¼› $\varepsilon _ { i t }$ è¡¨ç¤ºéšæœºè¯¯å·®ä¸”$\varepsilon _ { i t } { \sim } N ( 0 , \sigma _ { \varepsilon } ^ { 2 } )$ ï¼Œä»¤ $\mathbf { \Psi } ^ { \cdot } \varepsilon _ { i } = ( \varepsilon _ { i 1 } , \varepsilon _ { i 2 } , \cdots , \varepsilon _ { i t } ) ^ { T }$ ï¼Œåˆ™ $\varepsilon _ { i } { \sim } N ( 0 , \sigma _ { \varepsilon } ^ { 2 } R )$ ã€‚ $\mathbf { 1 } = ( 1 , 1 , \cdots , 1 ) ^ { T }$ è¡¨ç¤ºå…ƒç´ å…¨ä¸º1 çš„$t$ ç»´åˆ—å‘é‡ï¼Œ $R _ { t \times t }$ è¡¨ç¤º $\mathbf { \boldsymbol { t } } \times \mathbf { \boldsymbol { t } }$ ç»´å·¥ä½œç›¸å…³çŸ©é˜µã€‚æœ¬æ–‡ä»…è€ƒè™‘å¹³è¡¡æ•°æ®çš„æƒ…å†µï¼Œæ­¤æ—¶çš„å·¥ä½œç›¸å…³çŸ©é˜µä¸ºå¯¹ç§°çŸ©é˜µå³ $R ^ { T } = R$ ï¼Œä¸” $( R ^ { - 1 } ) ^ { T } = R ^ { - 1 }$ ã€‚éšæœºæ•ˆåº”ä¸éšæœºè¯¯å·®ä¸å­˜åœ¨ç›¸å…³æ€§ï¼Œå½¼æ­¤ä¹‹é—´ç›¸äº’ç‹¬ç«‹ï¼Œæ­¤æ—¶æ½œåœ¨å­ç»„æ¡ä»¶æ¨¡å‹ä¸€èˆ¬å½¢å¼å¦‚ä¸‹ï¼š

$$
y _ { i } | ( \delta _ { i } , U _ { i } , W _ { i } , b _ { i } ) = W _ { i } \alpha + { \bf 1 } b _ { i } + \varepsilon _ { i } , i = 1 , 2 , \dots , N
$$

åœ¨ $\delta _ { i } , U _ { i } , W _ { i }$ çš„æ¡ä»¶ä¸‹ï¼Œ $y _ { i }$ å’Œ $b _ { i }$ è”åˆæ­£æ€åˆ†å¸ƒå¦‚ä¸‹ï¼š

$$
\binom { y _ { i } } { b _ { i } } \sim N \left( \left[ \begin{array} { c c } { W _ { i } \alpha + \mathbf { 1 } \mu _ { i } } \\ { \mu _ { i } } \end{array} \right] , \left[ \begin{array} { c c } { \Sigma } & { B } \\ { B ^ { T } } & { \sigma _ { b } ^ { 2 } } \end{array} \right] _ { ( t + 1 ) \times ( t + 1 ) } \right)
$$

$$
\begin{array} { c } { \mu _ { i } = \mu _ { 1 } I ( \delta _ { i } = 1 ) + \mu _ { 2 } I ( \delta _ { i } = 2 ) + \mu _ { 3 } I ( \delta _ { i } = 3 ) } \\ { V a r ( y _ { i } ) = \Sigma = \mathbf { 1 } \sigma _ { b } ^ { 2 } \mathbf { 1 } ^ { T } + \sigma _ { \varepsilon } ^ { 2 } R _ { t \times t } } \\ { B = \mathbf { 1 } \sigma _ { b } ^ { 2 } } \\ { B ^ { T } = \sigma _ { b } ^ { 2 } \mathbf { 1 } ^ { T } } \end{array}
$$

æ ¹æ®é«˜æ–¯è”åˆåˆ†å¸ƒçš„æ¡ä»¶æœŸæœ›ä¸æ¡ä»¶æ–¹å·®å…¬å¼ï¼Œç»™å®š $U _ { i } , W _ { i }$ ä¸”åœ¨ $y _ { i }$ å’Œ $\delta _ { i }$ çš„æ¡ä»¶ä¸‹éšæœºæ•ˆåº” $b _ { i }$ çš„åéªŒå‡å€¼ä¸º

$$
\hat { b } _ { i } = E ( b _ { i } | y _ { i } , \delta _ { i } ) = \mu _ { i } + B ^ { T } \Sigma ^ { - 1 } ( y _ { i } - W _ { i } \alpha - \mathbf { 1 } \mu _ { i } )
$$

å¯¹äºæ¯ä¸ªå­ç»„ $k = 1 , 2 , 3$ æ—¶ï¼Œéšæœºæ•ˆåº” $b _ { i k }$ çš„åéªŒå‡å€¼ä¸º

$$
\hat { b } _ { i k } = E ( b _ { i } | y _ { i } , \delta _ { i } = k ) = \mu _ { k } + B ^ { T } \Sigma ^ { - 1 } ( y _ { i } - W _ { i } \alpha - \mathbf { 1 } \mu _ { k } )
$$

ç»™å®š $U _ { i } , W _ { i }$ ä¸”åœ¨ $y _ { i }$ å’Œ $\delta _ { i }$ çš„æ¡ä»¶ä¸‹éšæœºæ•ˆåº” $b _ { i }$ çš„åéªŒæ–¹å·®ä¸º

$$
\hat { \sigma } _ { b } ^ { 2 } = C o v ( b _ { i } | y _ { i } , \delta _ { i } ) = \sigma _ { b } ^ { 2 } - B ^ { T } \Sigma ^ { - 1 } B
$$

æ­¤å¤–ï¼Œç»™å®š $U _ { i } , W _ { i }$ ä¸”åœ¨ $y _ { i }$ å’Œ $\delta _ { i }$ çš„æ¡ä»¶ä¸‹éšæœºæ•ˆåº”çš„äºŒé˜¶çŸ© $b _ { i } b _ { i } ^ { T }$ çš„åéªŒä¼°è®¡ä¸º

$$
\boldsymbol { E } \big ( b _ { i } \boldsymbol { b } _ { i } ^ { T } \big | y _ { i } , \delta _ { i } = \boldsymbol { k } \big ) = \widehat { b } _ { i k } \widehat { \boldsymbol { b } } _ { i k } ^ { \ T } + \widehat { \sigma } _ { b } ^ { 2 }
$$

# 3.2 æ¨¡å‹å‚æ•°ä¼°è®¡åŠåˆ†ç»„

# 3.2.2 å‚æ•°ä¼°è®¡åŠåˆ†ç»„

æœ¬èŠ‚ä¸­æˆ‘ä»¬å°†éšæœºæ•ˆåº” $b _ { i }$ å’Œæ½œåœ¨å­ç»„å˜é‡ $\delta _ { i }$ çœ‹ä½œæ˜¯ç¼ºå¤±çš„ï¼Œå°†å¾…ä¼°è®¡å‚æ•°è®°ä½œğœƒä¸” $\theta =$ $( \gamma _ { 1 } , \gamma _ { 2 } , \gamma _ { 3 } , \mu _ { 1 } , \mu _ { 2 } , \mu _ { 3 } , \alpha , \sigma _ { \varepsilon } ^ { 2 } , \sigma _ { b } ^ { 2 } , R )$ ï¼Œåˆ™å®Œå…¨æ•°æ®çš„å¯¹æ•°ä¼¼ç„¶å‡½æ•°

$$
l ( \theta ) = \sum _ { i = 1 } ^ { N } \lbrace I ( \delta _ { i } = 1 ) l o g \pi ( U _ { i } \gamma _ { 1 } ) + I ( \delta _ { i } = 2 ) l o g \pi ( U _ { i } \gamma _ { 2 } ) + I ( \delta _ { i } = 3 ) l o g \pi ( U _ { i } \gamma _ { 3 } ) \rbrace
$$

$$
\begin{array} { l } { { + \displaystyle \sum _ { i = 1 } ^ { N } \lbrace I ( \delta _ { i } = 1 ) l o g \phi ( y _ { i } , W _ { i } \alpha + { \bf 1 } b _ { i } , \sigma _ { \varepsilon } ^ { 2 } R _ { t \times t } ) + I ( \delta _ { i } = 2 ) l o g \phi ( y _ { i } , W _ { i } \alpha + { \bf 1 } b _ { i } , \sigma _ { \varepsilon } ^ { 2 } R _ { t \times t } ) } } \\ { { + I ( \delta _ { i } = 3 ) l o g \phi ( y _ { i } , W _ { i } \alpha + { \bf 1 } b _ { i } , \sigma _ { \varepsilon } ^ { 2 } R _ { t \times t } ) \rbrace } } \\ { { + \displaystyle \sum _ { i = 1 } ^ { N } \lbrace I ( \delta _ { i } = 1 ) l o g \varphi ( b _ { i } , \mu _ { 1 } , \sigma _ { b } ^ { 2 } ) + I ( \delta _ { i } = 2 ) l o g \varphi ( b _ { i } , \mu _ { 2 } , \sigma _ { b } ^ { 2 } ) + I ( \delta _ { i } = 3 ) l o g \varphi ( b _ { i } , \mu _ { 3 } , \sigma _ { b } ^ { 2 } ) \rbrace } } \end{array}
$$

å…¶ä¸­ $\begin{array} { r } { \pi ( x ) = \frac { e ^ { x } } { \sum _ { k = 1 } ^ { 3 } e ^ { U _ { i } \gamma _ { k } } } } \end{array}$ è¡¨ç¤ºç”±å¤šé¡¹é€»è¾‘å›å½’æ±‚å¾—çš„éš¶å±å„å­ç»„çš„æ¦‚ç‡ã€‚ $\phi ( y _ { i } , W _ { i } \alpha +$ $\mathbf { 1 } b _ { i } , \sigma _ { \varepsilon } ^ { 2 } R _ { t \times t } )$ è¡¨ç¤ºæœŸæœ›ä¸º $W _ { i } \alpha + \mathbf { 1 } b _ { i }$ ï¼Œæ–¹å·®ä¸º $\sigma _ { \varepsilon } ^ { 2 } R _ { t \times t }$ ï¼Œ $y _ { i }$ çš„å¤šå…ƒæ­£æ€åˆ†å¸ƒçš„å¯†åº¦å‡½æ•°ã€‚$\varphi ( b _ { i } , \mu _ { k } , \sigma _ { b } ^ { 2 } )$ è¡¨ç¤ºæœŸæœ›ä¸º $\mu _ { k }$ ï¼Œæ–¹å·®ä¸º $\sigma _ { b } ^ { 2 }$ ï¼Œ $b _ { i }$ çš„ä¸€å…ƒæ­£æ€åˆ†å¸ƒçš„å¯†åº¦å‡½æ•°ã€‚ $I ( \cdot )$ è¡¨ç¤ºæŒ‡ç¤ºå‡½æ•°ï¼Œå…¶å–å€¼ä¸º 0 æˆ– 1ï¼Œå½“æŒ‡ç¤ºå‡½æ•°ä¸­çš„æ¡ä»¶åˆ¤æ–­å‘½é¢˜æˆç«‹æ—¶ï¼ŒæŒ‡ç¤ºå‡½æ•°å–å€¼ä¸º 1ï¼Œå¦åˆ™ä¸º $0$ ã€‚å¯¹äº $I ( \delta _ { i } = 1 )$ ï¼Œ $I ( \delta _ { i } = 2 )$ ï¼Œ $I ( \delta _ { i } = 3 )$ å½“æœ‰ä¸€ä¸ªæŒ‡ç¤ºå‡½æ•°å–å€¼ä¸º 1ï¼Œåˆ™å¦å¤–ä¸¤ä¸ªæŒ‡ç¤ºå‡½æ•°ä¸º 0ã€‚

ä¸‹é¢é€šè¿‡EM ç®—æ³•æ±‚å®Œå…¨æ•°æ®å¯¹æ•°ä¼¼ç„¶å‡½æ•°ä¸­çš„æœªçŸ¥å‚æ•°ã€‚

E æ­¥ï¼šç»™å®šå½“å‰çš„å‚æ•°ä¼°è®¡å€¼ $\theta ^ { ( j ) }$ ï¼Œæœ‰ $\mathrm { Q } \big ( \theta , \theta ^ { ( j ) } \big ) = I _ { 1 } + I _ { 2 } + I _ { 3 }$ ï¼Œå…·ä½“å¦‚ä¸‹ï¼š

$$
I _ { 1 } = \sum _ { i = 1 } ^ { N } \{ E ( I ( \delta _ { i } = 1 ) | y ) l o g \pi ( U _ { i } \gamma _ { 1 } ) + E ( I ( \delta _ { i } = 2 ) | y ) l o g \pi ( U _ { i } \gamma _ { 2 } ) + E ( I ( \delta _ { i } = 3 ) | ) l o g \pi ( U _ { i } \gamma _ { 3 } ) \}
$$

$$
\begin{array} { l } { { I _ { 2 } = - \displaystyle \frac { M } { 2 } l o g \sigma _ { \varepsilon } ^ { 2 } - \displaystyle \frac { N } { 2 } \log | R | } } \\ { { \displaystyle + \sum _ { i = 1 } ^ { N } \sum _ { k = 1 } ^ { 3 } - \displaystyle \frac { P ( \delta _ { i } = k | y ) } { 2 \sigma _ { \varepsilon } ^ { 2 } } ( \bigl ( y _ { i } - W _ { i } { \hat { \alpha } } - \mathbf { 1 } \hat { b } _ { i k } \bigr ) ^ { T } R ^ { - 1 } \bigl ( y _ { i } - W _ { i } { \hat { \alpha } } - \mathbf { 1 } \hat { b } _ { i k } \bigr ) + t r ( R ^ { - 1 } \mathbf { 1 } \hat { \sigma } _ { b } ^ { 2 } \mathbf { 1 } ^ { T } ) + \hat { \rho } _ { i k } \hat { \rho } _ { k } ^ { 2 } \mathbf { 1 } ^ { T } ) } } \end{array}
$$

$$
I _ { 3 } = - \frac { N } { 2 } l o g \sigma _ { b } ^ { 2 } + \sum _ { i = 1 } ^ { N } \sum _ { k = 1 } ^ { 3 } - \frac { P ( \delta _ { i } = k | y ) } { 2 \sigma _ { b } ^ { 2 } } \Big ( \big ( \hat { b } _ { i k } - \mu _ { k } \big ) ^ { 2 } + \hat { \sigma } _ { b } ^ { 2 } \Big )
$$

å…¶ä¸­ï¼Œ $\begin{array} { r } { \mathbf { M } = \sum _ { i = 1 } ^ { N } t = N t ; \hat { b } _ { i k } , \hat { \sigma } _ { b } ^ { 2 } } \end{array}$ åˆ†åˆ«è¡¨ç¤ºéšæœºæ•ˆåº”å±äºç¬¬ $k$ å­ç»„çš„åéªŒå‡å€¼å’ŒåéªŒæ–¹å·®ã€‚

ç»™å®šå½“å‰å‚æ•° $\theta ^ { ( j ) }$ ï¼Œå¯¹äº $i = 1 , 2 , \cdots , N$ ï¼Œä»¤

$$
P _ { i 1 } = P \big ( \delta _ { i } = 1 \big | y _ { i } , \theta ^ { ( j ) } \big )
$$

$$
\begin{array} { r l } & { = \frac { \pi ( U _ { i } \gamma _ { 1 } ^ { ( \beta ) } ) \phi ( y _ { i } , W _ { i } \alpha + \mu _ { 1 } ^ { ( \beta ) } , \Sigma _ { i } ^ { ( i ) } ) } { \pi ( U _ { i } \gamma _ { 1 } ^ { ( 1 ) } ) \phi ( y _ { i } , W _ { i } \alpha + \mu _ { 1 } ^ { ( \beta ) } , \Sigma _ { i } ^ { ( \beta ) } ) + \pi ( U _ { i } \gamma _ { 2 } ^ { ( 1 ) } ) \phi ( y _ { i } , W _ { i } \alpha + \mu _ { 2 } ^ { ( \beta ) } , \Sigma _ { i } ^ { ( i ) } ) + \pi ( U _ { i } \gamma _ { 3 } ^ { ( 0 ) } ) \phi ( y _ { i } , W _ { i } \alpha - \mu _ { 1 } ^ { ( \beta ) } ) } } \\ & { P _ { i 2 } = P ( \delta _ { i } = 2 | y _ { i } , \theta ^ { ( \beta ) } ) } \\ & { = \frac { \pi ( U _ { i } \gamma _ { 2 } ^ { ( \beta ) } ) \phi ( y _ { i } , W _ { i } \alpha + \mu _ { 1 } ^ { ( \beta ) } , \Sigma _ { i } ^ { ( \beta ) } ) } { \pi ( U _ { i } \gamma _ { 1 } ^ { ( 0 ) } ) \phi ( y _ { i } , W _ { i } \alpha + \mu _ { 2 } ^ { ( \beta ) } , \Sigma _ { i } ^ { ( i ) } ) + \pi ( U _ { i } \gamma _ { 3 } ^ { ( 0 ) } ) \phi ( y _ { i } , W _ { i } \alpha - \mu _ { 1 } ^ { ( \beta ) } ) } } \\ & { P _ { i 3 } = P ( \delta _ { i } = 3 | y _ { i } , \theta ^ { ( \beta ) } ) } \\ &  = \frac { \pi ( U _ { i } \gamma _ { 3 } ^ { ( \beta ) } ) \phi ( y _ { i } , W _ { i } \alpha + \mu _ { 1 } ^ { ( \beta ) } , \Sigma _ { i } ^ { ( \beta ) } ) + \pi ( U _ { i } \gamma _ { 3 } ^ { ( \beta ) } ) \phi ( y _ { i } , W _ { i } \alpha + \mu _ { 2 } ^ { ( \beta ) } , \Sigma _ { i } ^ { ( i ) } ) }  \pi ( U _ { i } \gamma _ { 1 } ^ { ( 1 ) } ) \phi ( y _ { i } , W _ { i } \alpha + \mu _ { 1 } ^ { ( \beta ) } , \Sigma _ { i } ^ { ( i ) } ) + \pi ( U _ { i } \gamma _ { 3 } ^ { ( \beta ) } ) \phi ( y _ { i } , W _ { i } \alpha + \mu _ { 2 } ^ { ( \beta ) } , \Sigma _ { i } ^  ( i \end{array}
$$

M æ­¥ï¼š $\theta ^ { ( j + 1 ) } = a r g m a x _ { \theta } Q \big ( \theta , \theta ^ { ( j ) } \big )$

ï¼ˆ1ï¼‰å…³äºå­ç»„éš¶å±å‚æ•° $\gamma _ { 1 }$ ã€ $\gamma _ { 2 }$ ã€ $\gamma _ { 3 }$ çš„è®¡ç®—ï¼š

$$
\begin{array} { r } { \gamma _ { 1 } ^ { ( j + 1 ) } = a r g m a x _ { \gamma _ { 1 } } P _ { i 1 } l o g \pi ( U _ { i } \gamma _ { 1 } ) + P _ { i 2 } l o g \pi ( U _ { i } \gamma _ { 2 } ) + P _ { i 3 } l o g \pi ( U _ { i } \gamma _ { 3 } ) } \\ { \gamma _ { 2 } ^ { ( j + 1 ) } = a r g m a x _ { \gamma _ { 2 } } P _ { i 1 } l o g \pi ( U _ { i } \gamma _ { 1 } ) + P _ { i 2 } l o g \pi ( U _ { i } \gamma _ { 2 } ) + P _ { i 3 } l o g \pi ( U _ { i } \gamma _ { 3 } ) } \\ { \gamma _ { 3 } ^ { ( j + 1 ) } = a r g m a x _ { \gamma _ { 3 } } P _ { i 1 } l o g \pi ( U _ { i } \gamma _ { 1 } ) + P _ { i 2 } l o g \pi ( U _ { i } \gamma _ { 2 } ) + P _ { i 3 } l o g \pi ( U _ { i } \gamma _ { 3 } ) } \end{array}
$$

ï¼ˆ2ï¼‰å…³äºå­ç»„å‡å€¼å‚æ•° $\cdot \mu _ { k } ( k = 1 , 2 , 3 )$ çš„è®¡ç®—:

$$
\mu _ { k } ^ { ( j + 1 ) } = \frac { \sum _ { i = 1 } ^ { N } P _ { i k } \hat { b } _ { i k } } { \sum _ { i = 1 } ^ { N } P _ { i k } }
$$

ï¼ˆ3ï¼‰å…³äºå‚æ•° $\hat { \alpha }$ çš„è®¡ç®—ï¼š

$$
\widehat { \boldsymbol { \alpha } } ^ { ( j + 1 ) } = \left( \sum _ { i = 1 } ^ { N } \sum _ { k = 1 } ^ { 3 } \boldsymbol { W _ { i } } ^ { T } \boldsymbol { R } ^ { - 1 } \boldsymbol { W _ { i } } \right) ^ { - 1 } \left( \sum _ { i = 1 } ^ { N } \sum _ { k = 1 } ^ { 3 } P _ { i k } \boldsymbol { W _ { i } } ^ { T } \boldsymbol { R } ^ { - 1 } \big ( y _ { i } - \mathbf { 1 } \widehat { b } _ { i k } \big ) \right)
$$

ï¼ˆ4ï¼‰å…³äºå‚æ•° $\sigma _ { b } ^ { 2 }$ ã€ $\sigma _ { \varepsilon } ^ { 2 }$ çš„è®¡ç®—ï¼š

$$
\sigma _ { b } ^ { 2 } ^ { ( j + 1 ) } = \frac { 1 } { N } \sum _ { i = 1 } ^ { N } \sum _ { k = 1 } ^ { 3 } ( P _ { i k } \big ( \widehat { b } _ { i k } - \mu _ { k } \big ) ^ { 2 } + \widehat { \sigma } _ { b } ^ { 2 } )
$$

$$
\sigma _ { \varepsilon } ^ { 2 ( j + 1 ) } = \frac { 1 } { M } \sum _ { i = 1 } ^ { N } \sum _ { k = 1 } ^ { 3 } ( P _ { i k } ( ( y _ { i } - W _ { i } \hat { \alpha } - \mathbf { 1 } \hat { b } _ { i k } ) ^ { T } R ^ { - 1 } \big ( y _ { i } - W _ { i } \hat { \alpha } - \mathbf { 1 } \hat { b } _ { i k } \big ) + t r ( R ^ { - 1 } \mathbf { 1 } \hat { \sigma } _ { b } ^ { 2 } \mathbf { 1 } ^ { T } ) )
$$

ï¼ˆ5ï¼‰å…³äºå‚æ•° $R$ çš„è®¡ç®—ï¼š

$$
R ^ { ( j + 1 ) } = \frac { 1 } { N \sigma _ { \mathscr { E } } ^ { 2 } } \sum _ { i = 1 } ^ { N } \sum _ { k = 1 } ^ { 3 } P _ { i k } ( \left( y _ { i } - W _ { i } \widehat { \alpha } - \mathbf { 1 } \widehat { b } _ { i k } \right) ( y _ { i } - W _ { i } \widehat { \alpha } - \mathbf { 1 } \widehat { b } _ { i k } ) ^ { T } + \mathbf { 1 } \widehat { \sigma } _ { b } ^ { 2 } \mathbf { 1 } ^ { T } )
$$

# 3.2.3 ä¼¼ç„¶æ¯”æ£€éªŒéªŒè¯å¤šé¡¹Logistic æ¨¡å‹ä¸­ä¸åˆ†ç»„æ¦‚ç‡æœ‰å…³çš„åå˜é‡

åŸå‡è®¾ï¼ˆ $( \mathsf { H O } )$ ï¼‰ï¼šç®€åŒ–æ¨¡å‹ä¸å®Œæ•´æ¨¡å‹åœ¨æ‹Ÿåˆè§‚æµ‹æ•°æ®ä¸Šæ— æ˜¾è‘—å·®å¼‚å¤‡æ‹©å‡è®¾ï¼ˆH1ï¼‰ï¼šå®Œæ•´æ¨¡å‹æ¯”ç®€åŒ–æ¨¡å‹å¯¹è§‚æµ‹æ•°æ®çš„æ‹Ÿåˆä¼˜åº¦æ˜¾è‘—æ›´å¥½è§‚æµ‹æ•°æ®çš„å¯¹æ•°ä¼¼ç„¶å‡½æ•°

$$
l _ { f u l l } = \sum _ { i = 1 } ^ { N } l o g \left( \sum _ { k = 1 } ^ { 3 } \pi ( U _ { i } \gamma _ { k } ) \phi ( y _ { i } , W _ { i } \alpha + \mathbf { 1 } \mu _ { k } , \boldsymbol { \Sigma } ) \right)
$$

$$
l _ { r e d u c e d } = \sum _ { i = 1 } ^ { N } l o g \left( \sum _ { k = 1 } ^ { 3 } \pi \big ( U ^ { * } { } _ { i } \gamma ^ { * } { } _ { k } \big ) \phi \big ( y _ { i } , W _ { i } \alpha ^ { * } + \mathbf { 1 } { \mu ^ { * } } _ { k } , { \Sigma ^ { * } } \big ) \right)
$$

æ£€éªŒç»Ÿè®¡é‡ï¼š

$$
\mathrm { L R } = 2 ( l _ { f u l l } - l _ { r e d u c e d } ) { \dot { \sim } } \chi ^ { 2 } ( d f )
$$

å…¶ä¸­ $\begin{array} { r } { \pi ( x ) = \frac { e ^ { x } } { \sum _ { k = 1 } ^ { 3 } e ^ { U _ { i } \gamma _ { k } } } ; } \end{array}$ è¡¨ç¤ºç”±å¤šé¡¹é€»è¾‘å›å½’æ±‚å¾—çš„éš¶å±å„å­ç»„çš„å…ˆéªŒæ¦‚ç‡ã€‚ $\phi ( y _ { i } , W _ { i } \alpha +$ $\mathbf { 1 } \mu _ { k } , \Sigma )$ è¡¨ç¤ºæœŸæœ›ä¸º $W _ { i } \alpha + \mathbf { 1 } \mu _ { k }$ ï¼Œæ–¹å·®ä¸º $\boldsymbol { \Sigma } = \mathbf { 1 } \sigma _ { b } ^ { 2 } \mathbf { 1 } ^ { T } + \sigma _ { \varepsilon } ^ { 2 } R _ { t \times t }$ ï¼Œ $y _ { i }$ çš„å¤šå…ƒæ­£æ€åˆ†å¸ƒçš„å¯†åº¦å‡½æ•°ã€‚$l _ { f u l l }$ å®Œæ•´æ¨¡å‹çš„å¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼Œ $l _ { r e d u c e d }$ è¡¨ç¤ºç®€åŒ–æ¨¡å‹çš„å¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼Œä¹Ÿå°±æ˜¯ä¸åŒ…å«å…¨éƒ¨åå˜é‡çš„æ¨¡å‹ã€‚å…¶ä¸­ï¼Œ $U _ { i }$ è¡¨ç¤ºæ‰€æœ‰è§‚æµ‹åˆ°çš„åå˜é‡ï¼Œ $\gamma _ { k } , \alpha , \mu _ { k }$ å’Œ $\Sigma$ æ˜¯åŸºäº $U _ { i }$ ä¸­åŒ…å«çš„åå˜é‡é€šè¿‡ EM ç®—æ³•ä¼°è®¡çš„å‚æ•°å€¼ï¼› $U ^ { * } { } _ { i }$ å°±è¡¨ç¤ºå‰”é™¤ä¸€éƒ¨åˆ†åå˜é‡ä¹‹åå‰©ä¸‹çš„è®¤ä¸ºä¸åˆ†ç»„æœ‰å…³çš„åå˜é‡ï¼Œ $\gamma _ { \textbf { \textit { k } } } ^ { * }$ ã€ $\alpha ^ { * }$ ã€ $\boldsymbol { \mu ^ { * } } _ { k }$ å’Œ $\Sigma ^ { * }$ æ˜¯åŸºäº $U ^ { * } { } _ { i }$ ä¸­åŒ…å«çš„åå˜é‡é€šè¿‡ EM ç®—æ³•ä¼°è®¡çš„å‚æ•°å€¼ã€‚ $d f$ è¡¨ç¤ºå®Œæ•´æ¨¡å‹ä¸ç®€åŒ–æ¨¡å‹çš„åå˜é‡æ•°é‡ä¹‹å·®
        loss = L_rec + lam1*L_deriv + lam2*L_curv + lam3*L_cons + lam4*L_T
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

